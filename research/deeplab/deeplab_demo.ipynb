{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLab Demo\n",
    "\n",
    "This demo will demostrate the steps to run deeplab semantic segmentation model on sample input images.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Running this demo requires the following libraries:\n",
    "\n",
    "* Jupyter notebook (Python 2)\n",
    "* Tensorflow (>= v1.5.0)\n",
    "* Matplotlib\n",
    "* Pillow\n",
    "* numpy\n",
    "* ipywidgets (follow the setup [here](https://ipywidgets.readthedocs.io/en/stable/user_install.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 17 09:43:56 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 390.12                 Driver Version: 390.12                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 34%   57C    P2    71W / 250W |  11763MiB / 12196MiB |     32%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 37%   62C    P2    74W / 250W |  11763MiB / 12196MiB |     30%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 24%   44C    P0    63W / 250W |      0MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 25%   45C    P0    63W / 250W |      0MiB / 12196MiB |      3%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      8347      C   python                                     11753MiB |\n",
      "|    1      1437      C   python                                     11753MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "0\r\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import StringIO\n",
    "import sys\n",
    "import tarfile\n",
    "import tempfile\n",
    "import urllib\n",
    "\n",
    "from IPython import display\n",
    "from ipywidgets import interact\n",
    "from ipywidgets import interactive\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "if tf.__version__ < '1.5.0':\n",
    "    raise ImportError('Please upgrade your tensorflow installation to v1.5.0 or newer!')\n",
    "\n",
    "# Needed to show segmentation colormap labels\n",
    "sys.path.append('utils')\n",
    "import get_dataset_colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and download models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84eeedb15f0f44dd9889e2056995ba3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description=u'model_name', options=('voc_google_trainaug', 'voc_mine', 'voc_google_trainval'), value='voc_google_trainaug'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {\n",
    "    'voc_mine': '/zfsauton/home/mbarnes1/deep_spectral_clustering/tensorflow/exp/VOC/train_on_train_set/train/000-semantic_Mar15-09:25:46_VCS-405b1e2_gpu8/graph.pbtxt',\n",
    "    'voc_google_trainaug': '/home/scratch/mbarnes1/data/models/tensorflow/deeplabv3_pascal_train_aug/frozen_inference_graph.pb',\n",
    "    'voc_google_trainval': '/home/scratch/mbarnes1/data/models/tensorflow/deeplabv3_pascal_trainval/frozen_inference_graph.pb'\n",
    "}\n",
    "\n",
    "Config = collections.namedtuple('Config', 'model_name, model_path')\n",
    "\n",
    "def get_config(model_name):\n",
    "    return Config(model_name, models[model_name])\n",
    "config_widget = interactive(get_config, model_name=models.keys(), model_dir='')\n",
    "display.display(config_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabModel(object):\n",
    "    \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
    "    \n",
    "    INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "    OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "    INPUT_SIZE = 513\n",
    "\n",
    "    def __init__(self, frozen_inference_graph_path):  # tarball_path):  # \n",
    "        \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
    "        self.graph = tf.Graph()\n",
    "        \n",
    "        graph_def = tf.GraphDef.FromString(open(frozen_inference_graph_path, 'rb').read())\n",
    "        \n",
    "        with self.graph.as_default():      \n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "        \n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "            \n",
    "    def run(self, image):\n",
    "        \"\"\"Runs inference on a single image.\n",
    "        \n",
    "        Args:\n",
    "            image: A PIL.Image object, raw input image.\n",
    "            \n",
    "        Returns:\n",
    "            resized_image: RGB image resized from original input image. \n",
    "            seg_map: Segmentation map of `resized_image`.\n",
    "        \"\"\"\n",
    "        width, height = image.size\n",
    "        print 'Input width {}, height {}'.format(width, height)\n",
    "        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "        target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "        resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
    "        print 'Resized image {}'.format(resized_image.size)\n",
    "        batch_seg_map = self.sess.run(\n",
    "            self.OUTPUT_TENSOR_NAME,\n",
    "            feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
    "        seg_map = batch_seg_map[0]\n",
    "        return resized_image, seg_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model voc_mine...\n"
     ]
    },
    {
     "ename": "DecodeError",
     "evalue": "Error parsing message",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDecodeError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-6d9a93010749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_widget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Loading model {}...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepLabModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-c6add1daa862>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, frozen_inference_graph_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozen_inference_graph_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDecodeError\u001b[0m: Error parsing message"
     ]
    }
   ],
   "source": [
    "config = config_widget.result\n",
    "print 'Loading model {}...'.format(config.model_name)\n",
    "model = DeepLabModel(config.model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAMES = np.asarray([\n",
    "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "    'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog',\n",
    "    'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\n",
    "    'train', 'tv'\n",
    "])\n",
    "\n",
    "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n",
    "FULL_COLOR_MAP = get_dataset_colormap.label_to_color_image(FULL_LABEL_MAP)\n",
    "\n",
    "\n",
    "def vis_segmentation(image, seg_map):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    grid_spec = gridspec.GridSpec(1, 4, width_ratios=[6, 6, 6, 1])\n",
    "\n",
    "    plt.subplot(grid_spec[0])\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('input image')\n",
    "    \n",
    "    plt.subplot(grid_spec[1])\n",
    "    seg_image = get_dataset_colormap.label_to_color_image(\n",
    "        seg_map, get_dataset_colormap.get_pascal_name()).astype(np.uint8)\n",
    "    plt.imshow(seg_image)\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation map')\n",
    "\n",
    "    plt.subplot(grid_spec[2])\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(seg_image, alpha=0.7)\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation overlay')\n",
    "    \n",
    "    unique_labels = np.unique(seg_map)\n",
    "    ax = plt.subplot(grid_spec[3])\n",
    "    plt.imshow(FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n",
    "    ax.yaxis.tick_right()\n",
    "    plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
    "    plt.xticks([], [])\n",
    "    ax.tick_params(width=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d407358e20c0479ebcf393fbf6edaaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description=u'image_name', options=('image1.jpg', 'image2.jpg', 'image3.jpg'), value='image1.jpg'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note that we are using single scale inference in the demo for fast\n",
    "# computation, so the results may slightly differ from the visualizations\n",
    "# in README, which uses multi-scale and left-right flipped inputs.\n",
    "\n",
    "IMAGE_DIR = 'g3doc/img'\n",
    "\n",
    "def run_demo_image(image_name):\n",
    "    try:\n",
    "        image_path = os.path.join(IMAGE_DIR, image_name)\n",
    "        orignal_im = Image.open(image_path)\n",
    "    except IOError:\n",
    "        print 'Failed to read image from %s.' % image_path \n",
    "        return \n",
    "    print 'running deeplab on image %s...' % image_name\n",
    "    resized_im, seg_map = model.run(orignal_im)\n",
    "    \n",
    "    vis_segmentation(resized_im, seg_map)\n",
    "\n",
    "_ = interact(run_demo_image, image_name=['image1.jpg', 'image2.jpg', 'image3.jpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on internet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18c37ae4a044014a5c273c9846a1da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Text(value=u'', description=u'url'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_an_internet_image(url):\n",
    "    if not url:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Prefix with 'file://' for local file.\n",
    "        if os.path.exists(url):\n",
    "            url = 'file://' + url\n",
    "        f = urllib.urlopen(url)\n",
    "        jpeg_str = f.read()\n",
    "    except IOError:\n",
    "        print 'invalid url: ' + url\n",
    "        return\n",
    "\n",
    "    orignal_im = Image.open(StringIO.StringIO(jpeg_str))\n",
    "    print 'running deeplab on image %s...' % url\n",
    "    resized_im, seg_map = model.run(orignal_im)\n",
    "    \n",
    "    vis_segmentation(resized_im, seg_map)\n",
    "\n",
    "_ = interact(get_an_internet_image, url='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
